__author__ = "DDSRem <https://ddsrem.com>"
__all__ = [
    "ShareP115Client",
    "iter_share_files_with_path",
    "get_pid_by_path",
    "get_pickcode_by_path",
    "iter_life_behavior_once",
]


from asyncio import sleep as async_sleep
from collections.abc import AsyncIterator, Container, Coroutine, Iterator
from dataclasses import dataclass
from functools import partial
from itertools import cycle
from os import PathLike
from pathlib import Path
from time import time, sleep
from typing import (
    Literal,
    List,
    Tuple,
    Dict,
    Any,
    Set,
    Optional,
    Callable,
)
from concurrent.futures import ThreadPoolExecutor, Future, as_completed

from iterutils import Yield, run_gen_step_iter
from p115client import P115Client, check_response
from p115client.tool.life import IGNORE_BEHAVIOR_TYPES, BEHAVIOR_TYPE_TO_NAME
from p115client.util import complete_url, posix_escape_name
from p115client.tool.attr import normalize_attr, get_id

from ..core.cache import idpathcacher
from ..db_manager.oper import FileDbHelper
from ..utils.limiter import ApiEndpointCooldown


class ShareP115Client(P115Client):
    """
    åˆ†äº«åŒæ­¥ä¸“ç”¨ Client
    """

    def share_snap_cookie(
        self,
        payload: dict,
        /,
        base_url: str | Callable[[], str] = "https://webapi.115.com",
        *,
        async_: Literal[False, True] = False,
        **request_kwargs,
    ) -> dict | Coroutine[Any, Any, dict]:
        """
        è·å–åˆ†äº«é“¾æ¥çš„æŸä¸ªç›®å½•ä¸­çš„æ–‡ä»¶å’Œå­ç›®å½•çš„åˆ—è¡¨ï¼ˆåŒ…å«è¯¦ç»†ä¿¡æ¯ï¼‰

        GET https://webapi.115.com/share/snap

        :payload:
            - share_code: str
            - receive_code: str
            - cid: int | str = 0
            - limit: int = 32
            - offset: int = 0
            - asc: 0 | 1 = <default> ğŸ’¡ æ˜¯å¦å‡åºæ’åˆ—
            - o: str = <default> ğŸ’¡ ç”¨æŸå­—æ®µæ’åº

                - "file_name": æ–‡ä»¶å
                - "file_size": æ–‡ä»¶å¤§å°
                - "user_ptime": åˆ›å»ºæ—¶é—´/ä¿®æ”¹æ—¶é—´
        """
        api = complete_url("/share/snap", base_url=base_url)
        payload = {"cid": 0, "limit": 32, "offset": 0, **payload}
        return self.request(url=api, params=payload, async_=async_, **request_kwargs)


def iter_share_files_with_path(
    client: str | PathLike | ShareP115Client,
    share_code: str,
    receive_code: str = "",
    cid: int = 0,
    order: Literal[
        "file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"
    ] = "user_ptime",
    asc: Literal[0, 1] = 1,
    max_workers: int = 25,
    speed_mode: Literal[0, 1, 2, 3] = 3,
    **request_kwargs,
) -> Iterator[dict]:
    """
    æ‰¹é‡è·å–åˆ†äº«é“¾æ¥ä¸‹çš„æ–‡ä»¶åˆ—è¡¨

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param share_code: åˆ†äº«ç æˆ–é“¾æ¥
    :param receive_code: æ¥æ”¶ç 
    :param cid: ç›®å½•çš„ id
    :param order: æ’åº

        - "file_name": æ–‡ä»¶å
        - "file_size": æ–‡ä»¶å¤§å°
        - "file_type": æ–‡ä»¶ç§ç±»
        - "user_utime": ä¿®æ”¹æ—¶é—´
        - "user_ptime": åˆ›å»ºæ—¶é—´
        - "user_otime": ä¸Šä¸€æ¬¡æ‰“å¼€æ—¶é—´

    :param asc: å‡åºæ’åˆ—ã€‚0: å¦ï¼Œ1: æ˜¯
    :param max_workers: æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°
    :param speed_mode: è¿è¡Œé€Ÿåº¦æ¨¡å¼
        0: æœ€å¿« (0.25s, 0.25s, 0.75s)
        1: å¿« (0.5s, 0.5s, 1.5s)
        2: æ…¢ (1s, 1s, 2s)
        3: æœ€æ…¢ (1.5s, 1.5s, 2s)

    :return: è¿­ä»£å™¨ï¼Œè¿”å›æ­¤åˆ†äº«é“¾æ¥ä¸‹çš„ï¼ˆæ‰€æœ‰æ–‡ä»¶ï¼‰æ–‡ä»¶ä¿¡æ¯
    """
    from .config import configer

    @dataclass
    class ApiEndpointInfo:
        """
        API ç«¯ç‚¹ä¿¡æ¯
        """

        endpoint: ApiEndpointCooldown
        api_name: str
        base_url: Optional[str] = None

    if isinstance(client, (str, PathLike)):
        client = ShareP115Client(client, check_for_relogin=True)
    speed_configs = {
        0: (0.25, 0.25, 0.75),
        1: (0.5, 0.5, 1.5),
        2: (1.0, 1.0, 2.0),
        3: (1.5, 1.5, 2.0),
    }
    app_http_cooldown, app_https_cooldown, api_cooldown = speed_configs.get(
        speed_mode, speed_configs[1]
    )
    snap_app_http_info = ApiEndpointInfo(
        endpoint=ApiEndpointCooldown(
            api_callable=lambda p: client.share_snap_app(
                p,
                base_url="http://pro.api.115.com",
                **request_kwargs,
                **configer.get_ios_ua_app(),
            ),
            cooldown=app_http_cooldown,
        ),
        api_name="share_snap_app_http",
        base_url="http://pro.api.115.com",
    )
    snap_app_https_info = ApiEndpointInfo(
        endpoint=ApiEndpointCooldown(
            api_callable=lambda p: client.share_snap_app(
                p,
                base_url="https://proapi.115.com",
                **request_kwargs,
                **configer.get_ios_ua_app(),
            ),
            cooldown=app_https_cooldown,
        ),
        api_name="share_snap_app_https",
        base_url="https://proapi.115.com",
    )
    snap_api_info = ApiEndpointInfo(
        endpoint=ApiEndpointCooldown(
            api_callable=lambda p: client.share_snap_cookie(
                p, **request_kwargs, **configer.get_ios_ua_app(app=False)
            ),
            cooldown=api_cooldown,
        ),
        api_name="share_snap",
        base_url=None,
    )
    repeating_pair = [snap_app_http_info, snap_app_https_info]
    first_page_api_pool = repeating_pair * 6
    first_page_api_pool.insert(6, snap_api_info)
    first_page_api_cycler = cycle(repeating_pair)

    def _job(
        api_info: ApiEndpointInfo,
        _cid: int,
        path_prefix: str,
        offset: int,
    ) -> Tuple[List[Dict[str, Any]], List[Tuple[int, str, int]]]:
        limit = 1_000
        if offset != 0:
            limit = 7_000
        payload = {
            "share_code": share_code,
            "receive_code": receive_code,
            "cid": _cid,
            "limit": limit,
            "offset": offset,
            "asc": asc,
            "o": order,
        }
        try:
            resp = api_info.endpoint(payload)
            check_response(resp)
        except Exception as e:
            api_info_str = f"API: {api_info.api_name}"
            if api_info.base_url:
                api_info_str += f", Base URL: {api_info.base_url}"
            api_info_str += f", Payload: {payload}"
            error_msg = f"{str(e)} | {api_info_str}"
            try:
                if e.args:
                    e.args = (error_msg,) + e.args[1:]
                else:
                    e.args = (error_msg,)
            except (TypeError, AttributeError):
                wrapper_msg = f"Exception occurred: {error_msg}"
                wrapper_e = RuntimeError(wrapper_msg)
                wrapper_e.__cause__ = e
                raise wrapper_e from e
            raise
        data = resp.get("data", {})
        count = data.get("count", 0)
        items = data.get("list", [])
        files_found = []
        subdirs_to_scan = []
        for attr in items:
            attr["share_code"] = share_code
            attr["receive_code"] = receive_code
            attr = normalize_attr(attr)
            name = posix_escape_name(attr["name"], repl="|")
            attr["name"] = name
            path = f"{path_prefix}/{name}" if path_prefix else f"/{name}"
            if attr["is_dir"]:
                subdirs_to_scan.append((int(attr["id"]), path, 0))
            else:
                attr["path"] = path
                files_found.append(attr)
        new_offset = offset + len(items)
        if new_offset < count and len(items) > 0:
            subdirs_to_scan.append((_cid, path_prefix, new_offset))
        return files_found, subdirs_to_scan

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        pending_futures: Set[Future] = set()
        initial_future = executor.submit(_job, next(first_page_api_cycler), cid, "", 0)
        pending_futures.add(initial_future)
        while pending_futures:
            for future in as_completed(pending_futures):
                pending_futures.remove(future)
                try:
                    files, subdirs = future.result()
                    for file_info in files:
                        yield file_info
                    for task_args in subdirs:
                        task_offset = task_args[2]
                        if task_offset > 0:
                            api_to_use = snap_api_info
                        else:
                            api_to_use = next(first_page_api_cycler)
                        new_future = executor.submit(_job, api_to_use, *task_args)
                        pending_futures.add(new_future)
                except Exception:
                    for f in pending_futures:
                        f.cancel()
                    executor.shutdown(wait=False, cancel_futures=True)
                    raise
                break


def get_pid_by_path(
    client: P115Client,
    path: str | PathLike | Path,
    mkdir: bool = True,
    update_cache: bool = True,
    by_cache: bool = True,
) -> int:
    """
    é€šè¿‡æ–‡ä»¶å¤¹è·¯å¾„è·å– ID

    :param client: 115 å®¢æˆ·ç«¯
    :param path: æ–‡ä»¶å¤¹è·¯å¾„
    :param mkdir: ä¸å­˜åœ¨åˆ™åˆ›å»ºæ–‡ä»¶å¤¹
    :param update_cache: æ›´æ–°æ–‡ä»¶è·¯å¾„ ID åˆ°ç¼“å­˜ä¸­
    :param by_cache: é€šè¿‡ç¼“å­˜è·å–

    :return int: æ–‡ä»¶å¤¹ IDï¼Œ0 ä¸ºæ ¹ç›®å½•ï¼Œ-1 ä¸ºè·å–å¤±è´¥
    """
    from .config import configer

    path = Path(path).as_posix()
    if path == "/":
        return 0
    if by_cache:
        pid = idpathcacher.get_id_by_dir(directory=path)
        if pid:
            return pid
    resp = client.fs_dir_getid(path, **configer.get_ios_ua_app(app=False))
    check_response(resp)
    pid = resp.get("id", -1)
    if pid == -1:
        return -1
    if pid == 0 and mkdir:
        resp = client.fs_makedirs_app(path, pid=0, **configer.get_ios_ua_app())
        check_response(resp)
        pid = resp["cid"]
        if update_cache:
            idpathcacher.add_cache(id=int(pid), directory=path)
        return pid
    if pid != 0:
        return pid
    return -1


def get_pickcode_by_path(
    client: P115Client,
    path: str | PathLike | Path,
) -> Optional[str]:
    """
    é€šè¿‡æ–‡ä»¶ï¼ˆå¤¹ï¼‰è·¯å¾„è·å– pick_code
    """
    from .config import configer

    db_helper = FileDbHelper()
    path = Path(path).as_posix()
    if path == "/":
        return None
    db_item = db_helper.get_by_path(path)
    if db_item:
        try:
            return db_item["pickcode"]
        except ValueError:
            return client.to_pickcode(db_item["id"])
    try:
        file_id = get_id(client=client, path=path, **configer.get_ios_ua_app(app=False))
        if file_id:
            return client.to_pickcode(file_id)
        return None
    except Exception:
        return None


def iter_life_behavior_once(
    client: str | PathLike | P115Client,
    from_id: int = 0,
    from_time: float = 0,
    type: str = "",
    ignore_types: None | Container[int] = IGNORE_BEHAVIOR_TYPES,
    date: str = "",
    first_batch_size=0,
    app: str = "ios",
    cooldown: float = 0,
    *,
    async_: Literal[False, True] = False,
    **request_kwargs,
) -> AsyncIterator[dict] | Iterator[dict]:
    """æ‹‰å–ä¸€ç»„ 115 ç”Ÿæ´»æ“ä½œäº‹ä»¶

    .. note::
        å½“ä½ æŒ‡å®šæœ‰ ``from_id != 0`` æ—¶ï¼Œå¦‚æœ from_time ä¸º 0ï¼Œåˆ™è‡ªåŠ¨é‡è®¾ä¸º -1

    .. caution::
        115 å¹¶æ²¡æœ‰æ”¶é›† å¤åˆ¶æ–‡ä»¶ å’Œ æ–‡ä»¶æ”¹å çš„äº‹ä»¶ï¼Œä»¥åŠç¬¬ä¸‰æ–¹ä¸Šä¼ å¯èƒ½ä¼šæ²¡æœ‰ ä¸Šä¼ äº‹ä»¶ ("upload_image_file" å’Œ "upload_file")

        ä¹Ÿæ²¡æœ‰ä»å›æ”¶ç«™çš„è¿˜åŸæ–‡ä»¶æˆ–ç›®å½•çš„äº‹ä»¶ï¼Œä½†æ˜¯åªè¦ä½ è¿˜åŸäº†ï¼Œä»¥å‰ç›¸åº”çš„åˆ é™¤äº‹ä»¶å°±ä¼šæ¶ˆå¤±

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param from_id: å¼€å§‹çš„äº‹ä»¶ id ï¼ˆä¸å«ï¼‰
    :param from_time: å¼€å§‹æ—¶é—´ï¼ˆå«ï¼‰ï¼Œè‹¥ä¸º 0 åˆ™ä»å½“å‰æ—¶é—´å¼€å§‹ï¼Œè‹¥ < 0 åˆ™ä»æœ€æ—©å¼€å§‹
    :param type: æŒ‡å®šæ‹‰å–çš„æ“ä½œäº‹ä»¶åç§°ï¼Œè‹¥ä¸æŒ‡å®šåˆ™æ˜¯å…¨éƒ¨
    :param ignore_types: ä¸€ç»„è¦è¢«å¿½ç•¥çš„æ“ä½œäº‹ä»¶ç±»å‹ä»£ç ï¼Œä»…å½“ `type` ä¸ºç©ºæ—¶ç”Ÿæ•ˆ
    :param date: æ—¥æœŸï¼Œæ ¼å¼ä¸º YYYY-MM-DDï¼Œè‹¥æŒ‡å®šåˆ™åªæ‹‰å–è¿™ä¸€å¤©çš„æ•°æ®
    :param first_batch_size: é¦–æ‰¹çš„æ‹‰å–æ•°ç›®
    :param app: ä½¿ç”¨æŸä¸ª app ï¼ˆè®¾å¤‡ï¼‰çš„æ¥å£
    :param cooldown: å†·å´æ—¶é—´ï¼Œå¤§äº 0 æ—¶ï¼Œä¸¤æ¬¡æ¥å£è°ƒç”¨ä¹‹é—´è‡³å°‘é—´éš”è¿™ä¹ˆå¤šç§’
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œäº§ç”Ÿ 115 ç”Ÿæ´»æ“ä½œäº‹ä»¶æ—¥å¿—æ•°æ®å­—å…¸
    """
    if isinstance(client, (str, PathLike)):
        client = P115Client(client, check_for_relogin=True)
    life_behavior_detail_cycle = cycle(
        [
            partial(client.life_behavior_detail, **request_kwargs),
            partial(client.life_behavior_detail_app, app=app, **request_kwargs),
        ]
    )
    if first_batch_size <= 0:
        first_batch_size = 64 if from_time or from_id else 1000
    if from_id and not from_time:
        from_time = -1

    def gen_step():
        payload = {"type": type, "date": date, "limit": first_batch_size, "offset": 0}
        seen: set[str] = set()
        seen_add = seen.add
        ts_last_call = time()
        resp = yield next(life_behavior_detail_cycle)(payload, async_=async_)
        events = check_response(resp)["data"]["list"]
        payload["limit"] = 1000
        offset = 0
        while events:
            for event in events:
                if (
                    from_id
                    and int(event["id"]) <= from_id
                    or from_time
                    and "update_time" in event
                    and int(event["update_time"]) < from_time
                ):
                    return
                event_type = event["type"]
                fid = event["file_id"]
                if fid not in seen:
                    if type or not ignore_types or event_type not in ignore_types:
                        event["event_name"] = BEHAVIOR_TYPE_TO_NAME.get(event_type, "")
                        yield Yield(event)
                    seen_add(fid)
            offset += len(events)
            if offset >= int(resp["data"]["count"]):
                return
            payload["offset"] = offset
            if cooldown > 0 and (delta := ts_last_call + cooldown - time()) > 0:
                if async_:
                    yield async_sleep(delta)
                else:
                    sleep(delta)
            ts_last_call = time()
            resp = yield next(life_behavior_detail_cycle)(payload, async_=async_)
            events = check_response(resp)["data"]["list"]

    return run_gen_step_iter(gen_step, async_)  # noqa
